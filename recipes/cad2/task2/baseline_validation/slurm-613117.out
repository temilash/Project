[2025-04-20 17:58:44,357][__main__][INFO] - Loading local model for Bassoon from /mnt/scratch/sc22ol/Project/recipes/cad2/task2/ConvTasNet/final_sd-sdr/Bassoon/best_model.safetensors
[2025-04-20 17:58:44,594][__main__][INFO] - Loading local model for Cello from /mnt/scratch/sc22ol/Project/recipes/cad2/task2/ConvTasNet/final_sd-sdr/Cello/best_model.safetensors
[2025-04-20 17:58:44,622][__main__][INFO] - Loading local model for Clarinet from /mnt/scratch/sc22ol/Project/recipes/cad2/task2/ConvTasNet/final_sd-sdr/Clarinet/best_model.safetensors
[2025-04-20 17:58:44,665][__main__][INFO] - Loading local model for Flute from /mnt/scratch/sc22ol/Project/recipes/cad2/task2/ConvTasNet/final_sd-sdr/Flute/best_model.safetensors
[2025-04-20 17:58:44,691][__main__][INFO] - Loading local model for Oboe from /mnt/scratch/sc22ol/Project/recipes/cad2/task2/ConvTasNet/final_sd-sdr/Oboe/best_model.safetensors
[2025-04-20 17:58:44,717][__main__][INFO] - Loading local model for Sax from /mnt/scratch/sc22ol/Project/recipes/cad2/task2/ConvTasNet/final_sd-sdr/Sax/best_model.safetensors
[2025-04-20 17:58:44,743][__main__][INFO] - Loading local model for Viola from /mnt/scratch/sc22ol/Project/recipes/cad2/task2/ConvTasNet/final_sd-sdr/Viola/best_model.safetensors
[2025-04-20 17:58:44,786][__main__][INFO] - Loading local model for Violin from /mnt/scratch/sc22ol/Project/recipes/cad2/task2/ConvTasNet/final_sd-sdr/Violin/best_model.safetensors
[2025-04-20 17:58:45,112][__main__][INFO] - [001/006] Processing S50001: song anitrasdance_001 for listener L5051
Error executing job with overrides: []
An error occurred during Hydra's exception formatting:
UnicodeDecodeError('utf-8', b'"""Evaluate the enhanced signals using the HAAQI metric."""\n\nfrom __future__ import annotations\n\n# pylint: disable=import-error\nimport hashlib\nimport json\nimport logging\nimport warnings\nfrom pathlib import Path\nfrom typing import Any\n\nimport hydra\nimport numpy as np\nimport pyloudnorm as pyln\nfrom numpy import ndarray\nfrom omegaconf import DictConfig\nimport scipy.signal as signal\n\nfrom clarity.enhancer.multiband_compressor import MultibandCompressor\nfrom clarity.evaluator.haaqi import compute_haaqi\nfrom clarity.utils.audiogram import Listener\nfrom clarity.utils.flac_encoder import read_flac_signal\nfrom clarity.utils.results_support import ResultsFile\nfrom clarity.utils.signal_processing import compute_rms, resample\n\nlogger = logging.getLogger(__name__)\n\n\ndef apply_frequency_gains(signal_data, sample_rate, frequencies, gains):\n    """Apply parametric EQ without ever dropping the original signal."""\n    # 1) Start from the original audio\n    output_signal = signal_data.copy()\n\n    # 2) If there are no bands or no non-zero gains, do nothing\n    if not frequencies or not gains or all(g == 0 for g in gains):\n        return output_signal\n\n    # 3) Accumulate only the filtered *difference* for bands with non-zero gain\n    for freq, gain_db in zip(frequencies, gains):\n        if gain_db == 0:\n            continue\n\n        # design a narrow \x93peak\x94 filter at this center frequency\n        b, a = signal.iirpeak(freq / (sample_rate / 2), Q=1.0)\n        filtered = signal.lfilter(b, a, signal_data)\n\n        # convert dB gain to linear\n        gain_lin = 10 ** (gain_db / 20)\n        # add/subtract only the *excess* band energy\n        output_signal += (filtered - signal_data) * (gain_lin - 1)\n\n    return output_signal\n\ndef apply_gains(stems: dict, sample_rate: float, gains: dict, listener: dict) -> dict:\n    """Apply instrument and listener-specific gains before remixing.\n\n    Args:\n        stems (dict): Dictionary of instrument stems (stereo signals).\n        sample_rate (float): Sample rate of the signal.\n        gains (dict): Dictionary containing instrument gain values.\n        listener (Listener): Listener object with audiogram information.\n\n    Returns:\n        dict: Dictionary of stems with correctly applied gains.\n    """\n    meter = pyln.Meter(int(sample_rate))\n\n    # Extract listener frequency bands and gain values\n    frequencies = listener.audiogram_left.frequencies\n    gain_left_freq = listener.audiogram_left.levels\n    gain_right_freq = listener.audiogram_right.levels\n\n    stems_gain = {}  # Initialize dictionary to store updated stems\n\n    for stem_str, stem_signal in stems.items():\n        if stem_signal.shape[0] < stem_signal.shape[1]:\n            stem_signal = stem_signal.T\n\n        # Compute current loudness for left and right channels\n        left_lufs = meter.integrated_loudness(stem_signal[:, 0])\n        right_lufs = meter.integrated_loudness(stem_signal[:, 1])\n\n        # Handle silent signals\n        if left_lufs == -np.inf:\n            left_lufs = -80\n        if right_lufs == -np.inf:\n            right_lufs = -80\n\n        # Retrieve instrument gain (default to 0 dB if missing)\n        instrument_gain = gains.get(stem_str, 0)\n\n        # Apply instrument gain\n        left_gain = left_lufs + instrument_gain\n        right_gain = right_lufs + instrument_gain\n\n        with warnings.catch_warnings():\n            warnings.filterwarnings("ignore", message="Possible clipped samples in output")\n            adjusted_left = pyln.normalize.loudness(stem_signal[:, 0], left_lufs, left_gain)\n            adjusted_right = pyln.normalize.loudness(stem_signal[:, 1], right_lufs, right_gain)\n\n        # Apply frequency-dependent listener-specific gains\n        adjusted_left = apply_frequency_gains(adjusted_left, sample_rate, frequencies, gain_left_freq)\n        adjusted_right = apply_frequency_gains(adjusted_right, sample_rate, frequencies, gain_right_freq)\n\n        # FIX: Store correctly in `stems_gain`\n        stems_gain[stem_str] = np.stack([adjusted_left, adjusted_right], axis=1)\n\n    #  Ensure all required stems are present before returning\n    if not stems_gain:\n        raise ValueError("Error: No stems were processed in apply_gains()!")\n\n    return stems_gain\n\n\n\ndef remix_stems(stems: dict) -> ndarray:\n    """Remix the stems into a stereo signal.\n\n    The remixing is done by summing the stems.\n\n    Args:\n        stems (dict): Dictionary of stems.\n\n    Returns:\n        ndarray: Stereo signal.\n    """\n    remix_signal = np.zeros(stems["source_1"].shape)\n    for _, stem_signal in stems.items():\n        remix_signal += stem_signal\n    return remix_signal\n\ndef make_scene_listener_list(scenes_listeners: dict, small_test: bool = False) -> list:\n    """Make the list of scene-listener pairing to process\n\n    Args:\n        scenes_listeners (dict): Dictionary of scenes and listeners.\n        small_test (bool): Whether to use a small test set.\n\n    Returns:\n        list: List of scene-listener pairings.\n\n    """\n    scene_listener_pairs = [\n        (scene, listener)\n        for scene in scenes_listeners\n        for listener in scenes_listeners[scene]\n    ]\n\n    # Can define a standard \'small_test\' with just 1/50 of the data\n    if small_test:\n        scene_listener_pairs = scene_listener_pairs[::400]\n\n    return scene_listener_pairs\n\n\ndef set_song_seed(song: str) -> None:\n    """Set a seed that is unique for the given song"""\n    song_encoded = hashlib.md5(song.encode("utf-8")).hexdigest()\n    song_md5 = int(song_encoded, 16) % (10**8)\n    np.random.seed(song_md5)\n\n\n\ndef load_reference_stems(music_dir: str | Path, stems: dict) -> dict[Any, ndarray]:\n    """Load the reference stems for a given scene.\n\n    Args:\n        music_dir (str | Path): Path to the music directory.\n        stems (dict): Dictionary of stems\n    Returns:\n        dict: Dictionary of reference stems.\n    """\n    reference_stems= {}\n    for source_id, source_data in stems.items():\n        if source_id == "mixture":\n            continue\n\n        stem, _= read_flac_signal(Path(music_dir) / source_data["track"])\n        reference_stems[source_id]= stem\n\n    return reference_stems\n\n\ndef adjust_level(signal: np.ndarray, gains_scene: dict) -> np.ndarray:\n    """\n    Adjust the level of the signal to compensate the effect of amplifying the\n    sources\n    """\n    dbi= np.array(list(gains_scene.values()))\n    dbn= -10 * np.log10(np.sum(10 ** (dbi / 10)) / dbi.shape[0])\n    return signal * 10 ** (dbn / 20)\n\n\n@ hydra.main(config_path="", config_name="config", version_base=None)\ndef run_calculate_aq(config: DictConfig) -> None:\n    """Evaluate the enhanced signals using the HAAQI metric."""\n\n    enhanced_folder= Path("enhanced_signals")\n    logger.info(f"Evaluating from {enhanced_folder} directory")\n\n    # Load listener audiograms and songs\n    listener_dict= Listener.load_listener_dict(config.path.listeners_file)\n\n    with Path(config.path.gains_file).open("r", encoding="utf-8") as file:\n        gains= json.load(file)\n\n    with Path(config.path.scenes_file).open("r", encoding="utf-8") as file:\n        scenes= json.load(file)\n\n    with Path(config.path.scene_listeners_file).open("r", encoding="utf-8") as file:\n        scenes_listeners= json.load(file)\n\n    with Path(config.path.music_file).open("r", encoding="utf-8") as file:\n        songs= json.load(file)\n\n        # Load compressor params\n    with Path(config.path.enhancer_params_file).open("r", encoding="utf-8") as file:\n        enhancer_params= json.load(file)\n\n    enhancer= MultibandCompressor(\n        crossover_frequencies = config.enhancer.crossover_frequencies,\n        sample_rate = config.input_sample_rate,\n    )\n\n    scores_headers= [\n        "scene",\n        "song",\n        "listener",\n        "left_haaqi",\n        "right_haaqi",\n        "avg_haaqi",\n    ]\n    if config.evaluate.batch_size == 1:\n        results_file= ResultsFile(\n            "scores.csv",\n            header_columns = scores_headers,\n        )\n    else:\n        results_file = ResultsFile(\n            f"scores_{config.evaluate.batch + 1}-{config.evaluate.batch_size}.csv",\n            header_columns=scores_headers,\n        )\n\n    scene_listener_pairs = make_scene_listener_list(\n', 1353, 1354, 'invalid start byte')
Traceback (most recent call last):
  File "/users/sc22ol/.conda/envs/clarity/lib/python3.8/site-packages/hydra/_internal/utils.py", line 291, in run_and_report
    traceback.print_exception(None, value=ex, tb=final_tb)  # type: ignore
  File "/users/sc22ol/.conda/envs/clarity/lib/python3.8/traceback.py", line 103, in print_exception
    for line in TracebackException(
  File "/users/sc22ol/.conda/envs/clarity/lib/python3.8/traceback.py", line 508, in __init__
    self.stack = StackSummary.extract(
  File "/users/sc22ol/.conda/envs/clarity/lib/python3.8/traceback.py", line 366, in extract
    f.line
  File "/users/sc22ol/.conda/envs/clarity/lib/python3.8/traceback.py", line 288, in line
    self._line = linecache.getline(self.filename, self.lineno).strip()
  File "/users/sc22ol/.conda/envs/clarity/lib/python3.8/linecache.py", line 16, in getline
    lines = getlines(filename, module_globals)
  File "/users/sc22ol/.conda/envs/clarity/lib/python3.8/linecache.py", line 47, in getlines
    return updatecache(filename, module_globals)
  File "/users/sc22ol/.conda/envs/clarity/lib/python3.8/linecache.py", line 137, in updatecache
    lines = fp.readlines()
  File "/users/sc22ol/.conda/envs/clarity/lib/python3.8/codecs.py", line 322, in decode
    (result, consumed) = self._buffer_decode(data, self.errors, final)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 1353: invalid start byte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "enhance.py", line 459, in <module>
    enhance()
  File "/users/sc22ol/.conda/envs/clarity/lib/python3.8/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/users/sc22ol/.conda/envs/clarity/lib/python3.8/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/users/sc22ol/.conda/envs/clarity/lib/python3.8/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/users/sc22ol/.conda/envs/clarity/lib/python3.8/site-packages/hydra/_internal/utils.py", line 302, in run_and_report
    raise ex
  File "/users/sc22ol/.conda/envs/clarity/lib/python3.8/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/users/sc22ol/.conda/envs/clarity/lib/python3.8/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/users/sc22ol/.conda/envs/clarity/lib/python3.8/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
  File "/users/sc22ol/.conda/envs/clarity/lib/python3.8/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/users/sc22ol/.conda/envs/clarity/lib/python3.8/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "enhance.py", line 416, in enhance
    stems = apply_gains(stems, config.input_sample_rate, gain_scene, listener)
  File "/mnt/scratch/sc22ol/Project/recipes/cad2/task2/baseline/evaluate.py", line 103, in apply_gains
  File "/mnt/scratch/sc22ol/Project/recipes/cad2/task2/baseline/evaluate.py", line 36, in apply_frequency_gains
ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
  File "evaluate.py", line 44
SyntaxError: Non-UTF-8 code starting with '\x93' in file evaluate.py on line 44, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details
Both scripts ran successfully!
